{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e95cd7f-d027-43eb-b0c5-763f00c9fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.spatial.transform import Rotation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/shihab/repo/src\")\n",
    "from analysis_utils import convert_to_tensors, shuffle_and_split, prepare_vectors\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(41)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee0ea69-9056-4d63-913b-db9d0a95e727",
   "metadata": {},
   "source": [
    "## Two body: Using New non-buggy data\n",
    "\n",
    "Along with comparsion with RPY\n",
    "\n",
    "Comment (4/26):\n",
    "+ We ignored a term so far: $V_{t} = f1(Xt, Xs).Fs + f2(Xt, Xs).Ft$\n",
    "\n",
    "Comments (03/18):\n",
    "\n",
    "+ The weird wave-y error plot for NN: converting ReLU's to Tanh got rid of those.\n",
    "+ Turns out we can remove the Tanh activation on the very last layer\n",
    "+ Looks like somewhere around 5-6 dist RPY overtakes us. Tried a little bit learning for larger distance- doesn't make much difference *for sphere*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79332c1d-4bd2-4a3f-a8cb-fa6aea5a69ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28000, 23),\n",
       " Index(['center_x', 'center_y', 'center_z', 'dist', 'min_dist', 'force_x',\n",
       "        'force_y', 'force_z', 'torque_x', 'torque_y', 'torque_z', 'vel_x',\n",
       "        'vel_y', 'vel_z', 'angvel_x', 'angvel_y', 'angvel_z', 'quat_6d_1',\n",
       "        'quat_6d_2', 'quat_6d_3', 'quat_6d_4', 'quat_6d_5', 'quat_6d_6'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"../data/sphere_2body_28k.csv\").drop(columns=['Unnamed: 0'])\n",
    "df.shape, df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a2823a9-0709-4a65-88bf-0716c0bf6416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df[\"dist\"], bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "624b7278-1425-47be-af9a-64821ee34db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vectors(df):\n",
    "    force_cols = ['force_x', 'force_y', 'force_z', \n",
    "                  \"torque_x\", \"torque_y\", \"torque_z\",]\n",
    "    output_cols = ['vel_x', 'vel_y', 'vel_z', 'angvel_x', 'angvel_y', 'angvel_z']\n",
    "    #feature_cols = [col for col in df.columns if col not in (force_cols + output_cols)]\n",
    "    feature_cols = ['center_x', 'center_y', 'center_z', 'dist', 'min_dist']\n",
    "    print(feature_cols)\n",
    "    \n",
    "    dist_vec = df[feature_cols].values\n",
    "    force_vec = df[force_cols].values\n",
    "    output_vec = df[output_cols].values\n",
    "    return dist_vec, force_vec, output_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e707fdd1-3d84-4da3-ba05-dcd32528599d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['center_x', 'center_y', 'center_z', 'dist', 'min_dist']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([22400, 5]), torch.Size([22400, 6]), torch.Size([5600, 5]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat, force, vel = prepare_vectors(df)\n",
    "feat, force, vel = convert_to_tensors(feat, force, vel)\n",
    "\n",
    "#vel *= 5\n",
    "\n",
    "tmp = list(shuffle_and_split(df, feat, force, vel, split_frac=.8))\n",
    "\n",
    "for i in range(len(tmp)):\n",
    "    tmp[i] = tmp[i].to(device)\n",
    "\n",
    "(train_dist_tensor, val_dist_tensor, \n",
    "    train_force_tensor, val_force_tensor, \n",
    "    train_velocity_tensor, val_velocity_tensor) = tmp\n",
    "\n",
    "train_dist_tensor.shape, train_force_tensor.shape, val_dist_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e3fe951-c5c2-436c-8785-d4186cc9216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1(d):\n",
    "    \"\"\" Computes the outer product of each 3D vector in the batch with itself. \"\"\"\n",
    "    # d: [batch_size, 3]\n",
    "    return torch.einsum('bi,bj->bij', d, d)  # [batch_size, 3, 3]\n",
    "\n",
    "def L2(d):\n",
    "    \"\"\" Returns the matrix (I - outer(d, d)) for each vector in the batch. \"\"\"\n",
    "    # Identity tensor expanded to batch size\n",
    "    batch_size = d.shape[0]\n",
    "    I = torch.eye(3).unsqueeze(0).repeat(batch_size, 1, 1).to(device)  # [batch_size, 3, 3]\n",
    "    ddT = torch.einsum('bi,bj->bij', d, d)  # [batch_size, 3, 3]\n",
    "    return I - ddT\n",
    "\n",
    "# Predefine the Levi-Civita tensor\n",
    "levi_civita = torch.zeros(3, 3, 3, dtype=torch.float)\n",
    "levi_civita[0, 1, 2] = 1\n",
    "levi_civita[1, 2, 0] = 1\n",
    "levi_civita[2, 0, 1] = 1\n",
    "levi_civita[0, 2, 1] = -1\n",
    "levi_civita[2, 1, 0] = -1\n",
    "levi_civita[1, 0, 2] = -1\n",
    "\n",
    "levi_civita = levi_civita.to(device)\n",
    "\n",
    "def L3(d):\n",
    "    \"\"\" Computes the cross product matrix for each 3D vector in the batch. \"\"\"\n",
    "    # Using einsum for batched matrix-vector multiplication:\n",
    "    return torch.einsum('ijk,bk->bij', levi_civita, d)  # [batch_size, 3, 3]\n",
    "\n",
    "def spsd_loss_func(sym_matrix, epsilon=1e-6):\n",
    "    \"\"\"SPSD loss representing SPSD violation\n",
    "    \"\"\"\n",
    "    eigenvalues = torch.linalg.eigvalsh(sym_matrix)  # (batch_size, 6)\n",
    "    negative_violations = torch.relu(-eigenvalues + epsilon)  # (batch_size, 6)\n",
    "    loss = torch.mean(negative_violations)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fba1a1-e763-4be5-854b-06c3db34b972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "160033d4-f092-4428-abec-ed52754e4de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "viscosity = 1.0\n",
    "eigens = []\n",
    "\n",
    "class ScNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ScNetwork, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 5),\n",
    "            #nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, r, print_scalars=False):\n",
    "        x = self.layers(r)\n",
    "        return x\n",
    "\n",
    "    def predict_mobility(self, X, print_scalars=False):\n",
    "        d_vec, r = X[:,:3], X[:,3]\n",
    "        sc = self.forward(X, print_scalars)\n",
    "\n",
    "        d_vec = -d_vec/ r.unsqueeze(-1) # negative,cz dvec=target-src\n",
    "        TT = sc[:, 0].unsqueeze(1).unsqueeze(2) * L1(d_vec) + \\\n",
    "                sc[:, 1].unsqueeze(1).unsqueeze(2) * L2(d_vec) # TODO: d_vec or r?\n",
    "        RT = sc[:, 2].unsqueeze(1).unsqueeze(2) * L3(d_vec)\n",
    "        RR = sc[:, 3].unsqueeze(1).unsqueeze(2) * L1(d_vec) + \\\n",
    "                sc[:, 4].unsqueeze(1).unsqueeze(2) * L2(d_vec)\n",
    "    \n",
    "        K = torch.zeros((len(X), 6, 6), dtype=torch.float32, device=X.device)\n",
    "\n",
    "        # After experiments, the kernel is NOT symmetric. \n",
    "        # Top-right and bottem left should NOT be transpose of each other\n",
    "        K[:, :3, :3] = TT  # Top-left block\n",
    "        K[:, 3:, :3] = RT  # Bottom-left block\n",
    "        K[:, :3, 3:] = RT  # Top-right block (transpose of B)\n",
    "        K[:, 3:, 3:] = RR  # Bottom-right block\n",
    "\n",
    "        nonSPD = 0\n",
    "        nonSym = 0\n",
    "        global eigens\n",
    "        if not self.training:\n",
    "            print(\"Activating SPSD check..\")\n",
    "            for i in range(len(K)):\n",
    "                k66 = K[i].detach().cpu()\n",
    "                eigs = np.linalg.eigvals(k66)\n",
    "                if not np.all(eigs>=- 1e-8):\n",
    "                    eigens.append((eigs.min(), eigs.max()))\n",
    "                    nonSPD += 1\n",
    "                if not np.allclose(k66, k66.T, atol=1e-4):\n",
    "                    nonSym += 1\n",
    "                    \n",
    "            print(f\"{nonSPD=}, {nonSym=}, {len(K)}\")\n",
    "        return K\n",
    "\n",
    "    def predict_velocity(self, X, force, return_M=False):\n",
    "        M = self.predict_mobility(X)/viscosity\n",
    "        velocity = torch.bmm(M, force.unsqueeze(-1)).squeeze(-1)\n",
    "        if return_M:\n",
    "            return velocity, M\n",
    "        return velocity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1014c0a1-1c7d-4ce3-b84a-2620831d4d56",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdf70f6d-c04d-4e7e-8d58-650e3fc3126c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 22272, 22400)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = train_dist_tensor.shape[1]\n",
    "batch_size = 256\n",
    "epochs = 400\n",
    "model = ScNetwork(input_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.50)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "#criterion = nn.MSELoss()\n",
    "n_iter = train_velocity_tensor.shape[0]//batch_size\n",
    "n_iter, n_iter*batch_size, len(train_dist_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73765d5c-4273-4c30-8bf5-1e29b86e0397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.15788470713914127\n",
      "Epoch 5, Loss: 0.021476243986566175\n",
      "Epoch 10, Loss: 0.015746659893628168\n",
      "Epoch 15, Loss: 0.01828235251850438\n",
      "Epoch 20, Loss: 0.012870740156149727\n",
      "Epoch 25, Loss: 0.01381278798069762\n",
      "Epoch 30, Loss: 0.011511810744802157\n",
      "Epoch 35, Loss: 0.00985372312174275\n",
      "Epoch 40, Loss: 0.0085991145293603\n",
      "Epoch 45, Loss: 0.008341974996287247\n",
      "Epoch 50, Loss: 0.008559147543648535\n",
      "Epoch 55, Loss: 0.006479548036131537\n",
      "Epoch 60, Loss: 0.006673780342178612\n",
      "Epoch 65, Loss: 0.00625355227518527\n",
      "Epoch 70, Loss: 0.005216437994084996\n",
      "Epoch 75, Loss: 0.004488592507082155\n",
      "Epoch 80, Loss: 0.005454472038659385\n",
      "Epoch 85, Loss: 0.0053252379072765855\n",
      "Epoch 90, Loss: 0.004597241208813657\n",
      "Epoch 95, Loss: 0.004350022790182768\n",
      "Epoch 100, Loss: 0.0037376474824616277\n",
      "Epoch 105, Loss: 0.0031482580963565015\n",
      "Epoch 110, Loss: 0.0038242787363585726\n",
      "Epoch 115, Loss: 0.0033893376473744198\n",
      "Epoch 120, Loss: 0.0030134037798056484\n",
      "Epoch 125, Loss: 0.003035928263200511\n",
      "Epoch 130, Loss: 0.00289557583030613\n",
      "Epoch 135, Loss: 0.002722524216227319\n",
      "Epoch 140, Loss: 0.0021910159554246857\n",
      "Epoch 145, Loss: 0.0021271983699487716\n",
      "Epoch 150, Loss: 0.0023725233121036455\n",
      "Epoch 155, Loss: 0.0025369613270821243\n",
      "Epoch 160, Loss: 0.0022153087781913495\n",
      "Epoch 165, Loss: 0.0018992353907797016\n",
      "Epoch 170, Loss: 0.001631215627535364\n",
      "Epoch 175, Loss: 0.0018721810681210167\n",
      "Epoch 180, Loss: 0.0017170654194986169\n",
      "Epoch 185, Loss: 0.0015108887007160262\n",
      "Epoch 190, Loss: 0.0015466842671920512\n",
      "Epoch 195, Loss: 0.001454521929336733\n",
      "Epoch 200, Loss: 0.0014778344675192032\n",
      "Epoch 205, Loss: 0.0016528056585229933\n",
      "Epoch 210, Loss: 0.0013919955771148804\n",
      "Epoch 215, Loss: 0.001383223497287381\n",
      "Epoch 220, Loss: 0.0011087123166780449\n",
      "Epoch 225, Loss: 0.001229012577029095\n",
      "Epoch 230, Loss: 0.0010030655024423339\n",
      "Epoch 235, Loss: 0.0010893628892392434\n",
      "Epoch 240, Loss: 0.001055731039344408\n",
      "Epoch 245, Loss: 0.0009313516637267566\n",
      "Epoch 250, Loss: 0.000939709071508855\n",
      "Epoch 255, Loss: 0.0008351976662772525\n",
      "Epoch 260, Loss: 0.0007755814261343758\n",
      "Epoch 265, Loss: 0.0007304262992760017\n",
      "Epoch 270, Loss: 0.0007132810417391445\n",
      "Epoch 275, Loss: 0.0006309301641250521\n",
      "Epoch 280, Loss: 0.0005591114823727858\n",
      "Epoch 285, Loss: 0.000574445015758854\n",
      "Epoch 290, Loss: 0.0005146812277259948\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m force \u001b[38;5;241m=\u001b[39m train_force_tensor[indices] \n\u001b[1;32m     23\u001b[0m Y \u001b[38;5;241m=\u001b[39m train_velocity_tensor[indices]  \n\u001b[0;32m---> 25\u001b[0m batch_output, M \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_velocity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_M\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m     28\u001b[0m data_loss \u001b[38;5;241m=\u001b[39m criterion(batch_output, Y)\n",
      "Cell \u001b[0;32mIn[7], line 60\u001b[0m, in \u001b[0;36mScNetwork.predict_velocity\u001b[0;34m(self, X, force, return_M)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_velocity\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, force, return_M\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 60\u001b[0m     M \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_mobility\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39mviscosity\n\u001b[1;32m     61\u001b[0m     velocity \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(M, force\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_M:\n",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m, in \u001b[0;36mScNetwork.predict_mobility\u001b[0;34m(self, X, print_scalars)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_mobility\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, print_scalars\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     23\u001b[0m     d_vec, r \u001b[38;5;241m=\u001b[39m X[:,:\u001b[38;5;241m3\u001b[39m], X[:,\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m---> 24\u001b[0m     sc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_scalars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     d_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39md_vec\u001b[38;5;241m/\u001b[39m r\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# negative,cz dvec=target-src\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     TT \u001b[38;5;241m=\u001b[39m sc[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m L1(d_vec) \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m     28\u001b[0m             sc[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m L2(d_vec) \u001b[38;5;66;03m# TODO: d_vec or r?\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m, in \u001b[0;36mScNetwork.forward\u001b[0;34m(self, r, print_scalars)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, print_scalars\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/_device.py:104\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def shuffle_tensors(*tensors):\n",
    "    \"\"\" Shuffles multiple tensors in the same order \"\"\"\n",
    "    indices = torch.randperm(tensors[0].size(0),device=device)  # Generate random indices\n",
    "    return tuple(tensor[indices] for tensor in tensors)\n",
    "    \n",
    "losses = []\n",
    "data_losses, spsd_losses = [], []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    avg = 0\n",
    "    avg_data, avg_spsd = 0, 0\n",
    "    \n",
    "    train_dist_tensor, train_force_tensor, train_velocity_tensor = shuffle_tensors(\n",
    "        train_dist_tensor, train_force_tensor, train_velocity_tensor\n",
    "    )\n",
    "    for it in range(n_iter):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        indices = torch.arange(it*batch_size, (it+1)*batch_size, dtype=torch.int).cuda()\n",
    "        \n",
    "        X = train_dist_tensor[indices]  \n",
    "        force = train_force_tensor[indices] \n",
    "        Y = train_velocity_tensor[indices]  \n",
    "    \n",
    "        batch_output, M = model.predict_velocity(X, force, return_M=True)\n",
    "\n",
    "        # Compute loss\n",
    "        data_loss = criterion(batch_output, Y)\n",
    "        spsd_loss = 0.0 * spsd_loss_func(M)\n",
    "        loss = data_loss + spsd_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        avg += loss.item()\n",
    "        avg_data += data_loss.item()\n",
    "        avg_spsd += spsd_loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    scheduler.step()\n",
    "    if epoch%5==0:\n",
    "        print(f'Epoch {epoch}, Loss: {avg/n_iter}')\n",
    "        losses.append(avg/n_iter)\n",
    "        data_losses.append(avg_data/n_iter)\n",
    "        spsd_losses.append(avg_spsd/n_iter)\n",
    "\n",
    "torch.save(model.state_dict(), \"sphere_2body.wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb5dcd1-4bf6-432e-8dff-52837043b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "los = losses[1:] # first one is usually too big, messes up the plot\n",
    "plt.plot(np.arange(len(los))*5+1, los);\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\");\n",
    "plt.savefig(\"loss.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24240720-39b0-4360-bbbb-cc6c339968ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP = 20\n",
    "los = data_losses[SKIP:] # first one is usually too big, messes up the plot\n",
    "plt.plot(np.arange(len(los))*5+1, los, label='data');\n",
    "\n",
    "los = spsd_losses[SKIP:] # first one is usually too big, messes up the plot\n",
    "plt.plot(np.arange(len(los))*5+1, los, label='spsd');\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\");\n",
    "plt.savefig(\"loss.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef92ec-80ab-4f11-9923-a1d45df8448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_losses[:5], data_losses[-5:], spsd_losses[:5], spsd_losses[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27add100-c5c5-4cae-9e3a-b990d064f0f2",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b064e-fd6f-4703-b6b6-498fc2bfb597",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScNetwork(input_dim).to(device)\n",
    "model.load_state_dict(torch.load(\"sphere_2body.wt\", weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "eigens = []\n",
    "with torch.no_grad():\n",
    "    val_output, M = model.predict_velocity(val_dist_tensor, val_force_tensor, return_M=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9a5897-58bc-480e-827d-a840cdb0eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41d58a3-acaa-456a-9556-95eba2c4b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(eigens))\n",
    "if eigens:\n",
    "    eigens = np.array(eigens)\n",
    "    plt.hist(eigens[:,0], bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e83fff-c71b-40da-923c-3f86f0c9b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False, precision=6)\n",
    "jj = 199\n",
    "val_output[jj], val_velocity_tensor[jj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4387198-f1e4-441b-a0d6-39ea60d5189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss(reduction='none') \n",
    "err = criterion(val_output, val_velocity_tensor)\n",
    "\n",
    "rmse = err.mean(axis=0)\n",
    "\n",
    "print(\"Root Mean Squared error for each of 6 output variables:\\n\", rmse)\n",
    "print(\"Actual Magnitude:\\n \", torch.abs(val_velocity_tensor).mean(axis=0))\n",
    "print(\"RMSE:\", err.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfaf267-c823-46fd-a6f4-733f03683bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Median Relative Absolute Error\n",
    "def mean_abs_err(val_output, val_velocity_tensor, npp=False):\n",
    "    # 6D vector: median % error for each vel component\n",
    "    valid_mask = torch.abs(val_velocity_tensor) > 1e-6\n",
    "    \n",
    "    filtered_y_tensor = torch.where(valid_mask, val_velocity_tensor, torch.tensor(float('nan')))\n",
    "    relative_error = torch.abs((val_output - filtered_y_tensor) / filtered_y_tensor)\n",
    "    \n",
    "    a = torch.nanmean(relative_error, dim=0)\n",
    "    return a*100\n",
    "\n",
    "mean_abs_err(val_output, val_velocity_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057f3d9-16c3-4657-9848-0cec8ac7bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "100*rmse/torch.abs(val_velocity_tensor).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724b1196-5e67-402a-81e9-dcb94b38c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = val_dist_tensor[:,3]<4.0\n",
    "mean_abs_err(val_output[idx], val_velocity_tensor[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5fbfb-a9ba-4c6c-95d5-97ac967e9b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = val_dist_tensor[:,3]<2.6\n",
    "mean_abs_err(val_output[idx], val_velocity_tensor[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b052a36-7bf5-472a-a705-e24bae8a1beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86dd9374-b0f7-4bb1-b523-b547eb508400",
   "metadata": {},
   "source": [
    "## Nearfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f5c308-11a9-4317-a6cb-10d63b5f3c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = torch.abs(val_output-val_velocity_tensor).mean(axis=1)\n",
    "\n",
    "tdf = pd.DataFrame({\n",
    "    'dist': val_dist_tensor[:,3].cpu().numpy(),\n",
    "    'err': err.detach().cpu().numpy()\n",
    "})\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.regplot(x='dist', y='err', data=tdf, scatter_kws={'color':'blue', 'alpha':0.15}, \n",
    "             line_kws={'color':'red'}, order=2);\n",
    "ax = sns.scatterplot(x='dist', y='err', data=tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff138401-fa82-4486-b566-fd70a78d68cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554ead5f-7dde-4db3-8820-9e17ac153cd7",
   "metadata": {},
   "source": [
    "## RPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755a75fc-e05c-4efa-b2a4-b5e1c847815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "viscosity = 1.0\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/shihab/hignn')\n",
    "from grpy_tensors import mu  #using non-torch original version\n",
    "\n",
    "def compute_rpy_mobility(c2, return_k=False):\n",
    "    global viscosity\n",
    "    c = np.array([[0.0, 0.0, 0.0], list(c2)])\n",
    "    radii = np.array([1.0, 1.0])  # Example radii of the particles\n",
    "    \n",
    "    M = mu(c, radii,blockmatrix=True)/viscosity\n",
    "    res = M[:,:,0,1,:,:] #M_ji, not M_ij. (RT,TR components vary)\n",
    "    K = np.zeros((6,6))\n",
    "    K[:3,:3] = res[0,0]\n",
    "    K[:3,3:] = res[0,1]\n",
    "    K[3:,:3] = res[1,0]\n",
    "    K[3:,3:] = res[1,1]\n",
    "\n",
    "    #K = M\n",
    "    return K\n",
    "\n",
    "len_val = len(val_dist_tensor)\n",
    "val_dist_arr = val_dist_tensor.cpu().numpy()\n",
    "val_force_arr = val_force_tensor.cpu().numpy()\n",
    "val_velocity_arr = val_velocity_tensor.cpu().numpy()\n",
    "rpy_vels = np.zeros((len_val,6))\n",
    "for i in range(len_val):\n",
    "    x,f = val_dist_arr[i], val_force_arr[i]\n",
    "    #f = np.concatenate((np.zeros_like(f), f))\n",
    "    yp = compute_rpy_mobility(x[:3]) @ f\n",
    "    rpy_vels[i] = yp[:6]\n",
    "\n",
    "rpy_vels_tensor = torch.Tensor(rpy_vels).cuda()\n",
    "mean_abs_err(rpy_vels_tensor, val_velocity_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3642986-dec8-4632-82ad-c58537346d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_abs_err(val_output, val_velocity_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dc34d3-b224-4de5-8e8c-448eb0f86691",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 16\n",
    "rpy_vels_tensor[ii], val_velocity_tensor[ii], val_output[ii], val_dist_arr[ii, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc3692a-d1c6-48d8-8353-a46dfbeea7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e2b380-bfc3-4363-a354-5d76cda45a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpy_err = torch.abs(rpy_vels_tensor-val_velocity_tensor).mean(axis=1)\n",
    "\n",
    "tdf['rpy_err'] = rpy_err.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ba34a-cce1-4c70-9a86-f89c804f54c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa81407-a70c-43ed-b8d4-0b31925e4d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_err_plot(tdf, rpy_plot=True):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams.update({'font.size': 16})  # Adjust the font size as needed\n",
    "\n",
    "    # Create a figure and a single axes object\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Scatter plot for NN-based tensor error\n",
    "    sns.scatterplot(x='dist', y='err', data=tdf, ax=ax,\n",
    "                    color='blue', alpha=0.15, label='NN-based Tensor')\n",
    "\n",
    "    # Scatter plot for RPY tensor error\n",
    "    if rpy_plot:\n",
    "        sns.scatterplot(x='dist', y='rpy_err', data=tdf, ax=ax,\n",
    "                        color='orange', alpha=0.15, label='RPY Tensor')\n",
    "\n",
    "    # Set axis labels\n",
    "    ax.set_xlabel(\"Pair Particle Distance\")\n",
    "    ax.set_ylabel(\"Error\")\n",
    "\n",
    "    # Create legend\n",
    "    ax.legend(title='Legend')\n",
    "\n",
    "    # Save and show the plot\n",
    "    plt.savefig(\"rpy_vs_nn.png\")\n",
    "    plt.show()\n",
    "\n",
    "show_err_plot(tdf, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a321c3-e40c-4a47-8247-0870a806211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lim = 4.0\n",
    "show_err_plot(tdf[tdf['dist']<Lim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aed6b4-bb35-481a-a355-c5f9619c7329",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (tdf['dist']>=3.0) & (tdf['dist']<6.0)\n",
    "show_err_plot(tdf[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654faa2-f897-46c2-a459-14e509a1c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (tdf['dist']>=4.0) & (tdf['dist']<6.0)\n",
    "show_err_plot(tdf[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9375fd-938a-4b15-b3a1-62d1fcf6b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (tdf['dist']>=6.0) & (tdf['dist']<8.0)\n",
    "show_err_plot(tdf[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce432d9-28ef-4de2-bb94-059423bce0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"vel_x\", \"vel_y\", \"vel_z\",\n",
    "    \"angvel_x\", \"angvel_y\", \"angvel_z\"]\n",
    "xdf = df[df['dist']>6.0]\n",
    "np.abs(xdf[cols]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d60e2-f37c-48ff-b550-95e124399363",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf = df[df['dist']<8.0]\n",
    "np.abs(xdf[cols]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644e6de-e91a-45e6-baa2-6df514e4bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = .416\n",
    "p = .432\n",
    "\n",
    "abs(t-p)/t*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ab274-0958-452d-a8d7-203bea8e8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = .07824\n",
    "p = .0897\n",
    "\n",
    "abs(t-p)/t*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699991b8-ff10-4486-897a-239ddbfbfb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.31859\n",
    "p = 0.330\n",
    "\n",
    "abs(t-p)/t*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a252ab-0992-418f-8412-37b19368e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.06925\n",
    "p = 0.07312\n",
    "\n",
    "abs(t-p)/t*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a4350-ef02-4eb0-af29-237fff334d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5982a9-db8a-4c44-af1f-ba723a453f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
